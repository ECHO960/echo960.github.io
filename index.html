<!DOCTYPE HTML>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0">
<!--[if lt IE 9]>
<script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->

<!-- END OF DON'T TOUCH -->

<!-- Website Title -->
<title>Chunhui Liu</title>
<!-- END OF Website Title -->

<!--  Website description -->
<meta name="description" content="Chunhui Liu - Welcome to my website! Here you will find all of my information.">
<!-- END OF Website description -->

<!-- DON'T TOUCH THIS SECTION -->
<link href='http://fonts.googleapis.com/css?family=Lato:300,400,700|Cookie' rel='stylesheet' type='text/css'>
<link rel="stylesheet" type="text/css" href="css/style.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js"></script>
<script src="scripts/jquery.carouFredSel-5.5.2.js" type="text/javascript"></script>
<script type="text/javascript" src="scripts/jquery.easing.1.3.js"></script>
<script type="text/javascript" src="scripts/jquery.form.js"></script> 
<script type="text/javascript" src="scripts/scripts.js"></script> 
</head>
<!-- END OF DON'T TOUCH -->

<style type="text/css">
.proj_content p>a {
    display: inline-block;
    padding: 2px 4px;
    font-size: 12px;
    font-weight: bold;
    line-height: 14px;
    color: #ffffff;
    text-shadow: 0 -1px 0 rgba(0, 0, 0, 0.25);
    white-space: nowrap;
    vertical-align: baseline;
    background-color: #999999;
	border-radius: 3px;
	margin-top: 4px;
	margin-right: 6px;
}

.main hr {
	color: #00ffff;
}
p {padding: 0}
</style>

<body>

<div class="wrapper">

    <hr/>
    <header>	<!-- Header Title Start -->
        <h1>
            <a href="https://echo960.github.io/"><img src="images/LCH.jpg" height="224" width="224"></a>
    	</h1>
        <h1> <span >Chunhui Liu</span></h1>
        
        <h2 style="padding-left: "> <h2>Hi, I am Chunhui, from PKU and major in Computer Science. I find it interesting to understand how the visual world is understood. Thus, I have done several work on Computer Vision task: (1) Action Analysis (2) Interpretability of Deep Networks. Moreover, I have been playing violin for 12 years. I find that it can calm my mind and give me fantastic insights from nowhere.</h2></h2>
    
    </header>	<!-- Header Title End -->

    
    <aside class="main">
    	<h3> Education</h3>
    		<ul>
        	  <li>
        	      <p> Peking University (PKU) <p>
        	      <p> <i>2014 Undergraduate </i>, The School of Electronics Engineering and Computer Science (EECS).</p>
        	      <P> Major in <i>Computer Science and Technology</i> </P>
        	  </li>
        	</ul>
      	<br/>
    	<h3>Research Experiences</h3>
        	<ul>
        	    <li>
        	        <p>Intern (03/2016 - present) <p>
        	        <p>Advisor: <a href="http://www.icst.pku.edu.cn/struct/people/liujiaying.html">Jiaying Liu</a>, Associate Professor, <a href="	http://www.icst.pku.edu.cn/struct/">Spatial and Temporal Restoration, Understanding and Compression Team(STRUCT),</a> <a href="	http://www.icst.pku.edu.cn/">Institute of Computer Science and Technology (ICST)</a>, Peking University</p>
        	    </li>
        	    </br>
        	    <li>
        	        <p>Summer Intern (06/2017 - 09/2017) <p>
        	        <p>Advisor: <a href="https://www.cs.cmu.edu/~deva/">Deva Ramanan</a>, Associate Professor, <a href="https://www.ri.cmu.edu/">	Robotics Institute</a>, <a href="https://www.cmu.edu/">Carnegie Mellon University</a></p>
        	    </li>
        	</ul>
 		<br/>
		<h3>Publications</h3>
    		<table class="proj_content" >
    			<tr><td colspan="2"><div class="archive-separator"></div></td></tr>
				<tr>
        	      <td style="width:20%"><img src="images/projects/Liu_Do.PNG" width="180" /> </td>
				  <td style="width:80%; padding-left: 10px"><p><font size="4"><b>Do Convolutional Neural Networks act as Compositional Nearest 	Neighbors?</b></font>  <font size="3"><br/>
        	         <u>Chunhui Liu</u>, Aayush Bansal, Victor Fragoso, Deva Ramanan<br />
					</font>
					<font size="3"><p><i>Arxiv preprint 1711.10683.</i>&nbsp;</p>
					<p><a href="papers/lch_doCNN.pdf">PDF</a></p></font></td>
			  	</tr>
			  
	
    			<tr><td colspan="2"><div class="archive-separator"></div></td></tr>
				<tr>
        	      <td style="width:20%"><img src="images/projects/Liu_PKU.png" width="180" /> </td>
				  <td style="width:80%; padding-left: 10px"><p><font size="4"><b>PKU-MMD: A Large Scale Benchmark for Skeleton-Based Human Action 	Understanding.</b></font>  <font size="3"><br/>
        	         <u>Chunhui Liu</u>, Yueyu Hu, Yanghao Li, Sijie Song, and Jiaying Liu<br />
					</font>
					<font size="3"><p><i>ACM Multimedia (ACM MM) Workshop, Silicon Valley, California, U.S., Oct. 2017.</i>&nbsp;</p>
					<p><a href="http://www.icst.pku.edu.cn/struct/Projects/PKUMMD.html">Project</a>&nbsp;&nbsp;<a href="papers/lch_mm17.pdf">PDF</a>&nbsp;&nbsp; <a href="https://github.com/ECHO960/PKU-MMD">Code</a>&nbsp;&nbsp; <a href="https://drive.google.com/drive/folders/0B20a4UzO-OyMUVpHaWdGMFY1VDQ">Dataset</a></p></font></td>
			  	</tr>
		
				<tr><td colspan="2"><div class="archive-separator"></div></td></tr>
				<tr>
        	      <td style="width:20%"><img src="images/projects/Hu_Temporal.JPG" width="180" /> </td>
				  <td style="width:80%; padding-left: 10px"><p><font size="4"><b>Temporal Perceptive Network for Skeleton-Based Action Recognition.	</b></font>  <font size="3"><br/>
        	         Yueyu Hu, <u>Chunhui Liu</u>, Yanghao Li, Sijie Song and Jiaying Liu<br/>
					</font>
					<font size="3"><p><i>British Machine Vision Conference (BMVC), London, UK, Sep. 2017.</i>&nbsp;</p>
					<p><a href="papers/huyy_bmvc17.pdf">PDF</a></p></font></td>
			  	</tr>
			 
			 	<tr><td colspan="2"><div class="archive-separator"></div></td></tr>
				<tr>
        	      <td style="width:20%"><img src="images/projects/Liu_online.PNG" width="180" /> </td>
				  <td style="width:80%; padding-left: 10px"><p><font size="4"><b>Online Action Detection and Forecast via Multi-Task Deep Recurrent 	Neural Network.</b></font>  <font size="3"><br/>
        	         <u>Chunhui Liu</u>, Yanghao Li, Yueyu Hu and Jiaying Liu<br/>
					</font>
					<font size="3"> <p><i>IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP2017), New Orleans, LA, 	U.S., March. 2017.</i></p>
					<p><a href="http://www.icst.pku.edu.cn/struct/Projects/multitask_OAD.html">Project</a>&nbsp;&nbsp;<a href="papers/lch_icassp17.pdf">PDF</a></p></font>
				  </td>
			  	</tr>
			  </table>
		  <tr><td colspan="2"><div class="archive-separator"></div></td></tr>
		<br/>
        <h3>Awards</h3>
        	<ul>
        	    <li>
        	        <p>1st Rank Award</p>
        	        <p><a href="http://rose1.ntu.edu.sg/ActionRecognitionChallenge/index.asp">ACCV 2016 Workshop "Large Scale 3D Human 	Activity Analysis Challenge in Depth Videos"</a>,  2016 </p>
        	    </li>
        	    <li>
        	        <p>Meritorious Winner</p>
        	        <p><a href="http://www.comap.com/undergraduate/contests/">Mathematical Contest In Modeling / 	Interdisciplinary Contest In Modeling (MCM/ICM)</a>,  2016 </p>
        	    </li>
        	    <li>
        	        <p>Bronze Prize </p>
        	        <p><a href="http://www.noi.cn/">National Olympiad in Informatics (NOI)</a>, 2013</p>
        	    </li>
        	</ul>
        <br/>
        <h3>Fragments of My Mind</h3>
            <ul>
                <li>
                    <p>Due to numerous parameters, to completely interpret Neural Networks is hard. However, recall how we learn and understand <i>the unknowns</i> : to compare it with <i>the knowns</i>. This is how I plan to open the black box of DNNs: design a interpretable approach to simulate the results of DNNs. Moreover, we are guessing that Neural Networks learn a new concept by comparing <i>the unknowns</i> with the training samples!
                    </p>
                </li>
                <li>
                    <p>When we are recognizing a new activity, we are not combine the confidence of each frame. Assuming an activity with a strange start and process, but a definite end, we will classify the action by a process from feeling curious to being sure. Temporal attention is a solution. But the on-line action analysis is the one on my mind!
                    </p>
                </li>
            </ul>
    </aside>
    <hr/>
</div>

     			
     			
<footer id="footer">  
		<h4>More About Me</h4>
     	<div class="info">
     		<section class="left social">
     		<div class="icon">
     			<a href="https://github.com/ECHO960">
     			<img src="images/icon/color-github.png" width="40">
     			</a>
     		</div>
     		<div class="icon">
     			<a href="https://www.facebook.com/ECHO960">
     			<img src="images/icon/color-facebook.png" width="40">
     			</a>
     		</div>
     		<div class="icon">
     			<a href="http://www.google.cn/maps/dir//39.9896298,116.3059584/@39.9889391,116.3052339,18z/data=!4m2!4m1!3e0">
     			<img src="images/icon/color-map.png" width="40">
     			</a>
     		</div>
     		</section>
     		<section class=" social">
     		Chunhui Liu [<a href="files/CV.pdf" style="color:#07F"> CV </a>]<br/>
     		E-mail: liuchunhui@pku.edu.cn
     		</section>
        </div> 
      
    
</footer>

</body>
</html>
