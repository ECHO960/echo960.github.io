<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Chunhui Liu</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link rel="stylesheet" href="css/normalize.css">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="css/cayman.css">
    <link rel="stylesheet" href="css/timeline.css">
  </head>
  <body>
    <section class="page-header">
      <img src="images/self.jpg" style="max-width:15%;">

      <h1 class="project-name">CHUNHUI LIU</h1>
      <h2 class="project-tagline">APPLIED SCIENETIST @ AMAZON AI
        </br> COMPUTER VISION DEVELOPER AND RESEARCHER
        <!-- </br> STRONG ARTIFICIAL INTELLIGENCE BELIEVER  -->
      </h2>

      <a href="files/Resume_chunhuiliu.pdf" class="btn">Resume</a>
      <!-- <a href="#" class="btn">GitHub</a> -->
      <a href="https://www.linkedin.com/in/chunhui-liu-65081b12b/" class="btn">LinkedIn</a>
      <a href="https://scholar.google.com/citations?user=03DnyVsAAAAJ&hl=en" class="btn">Google Scholar</a>
      <!-- <a href="#" class="btn">Download .tar.gz</a> -->
    </section>

    

    <section class="main-content">
      <p> Greetings. My name is Chunhui Liu and I am an applied scientist from Amazon AWS Rekognition Team. I am working on understanding visual concepts in video domain. That contains action/activity understanding, movie/story understanding. I obtained my Master degree in Computer Vision from Carnegie Mellon University. Before that, I obtained my Bachelor degree from Peking University in China.</p>
      <!-- </br> -->
     <!--  <p>
      I am so excited about the progress <i>Deep Learning</i> have made so far. But as a strong AI believer, I know we are far from our destination. 
      </p>
 -->      <HR style="FILTER: alpha(opacity=100,finishopacity=0,style=3)" width="100%" color=#987cb9 SIZE=3>
      
      <!-- Experiences -->
      <h1>
        Experiences
      </h1>
      <div class="timeline">
        <div class="entry">
          <div class="title">
            <h3>Applied Scientist, Amazon AWS</h3>
            <p>2020.2 - present</p>
          </div>
          <div class="body">
            <p>Rekognition Group, Seattle</p>
            <ul>
                <li>Worked on Spatial Temporal Action Recognition and Detection.</li>
                <li>Working on Movie Scene Detection.</li>
                </br>
             </ul>
          </div>
        </div>

        <div class="entry">
          <div class="title">
            <h3>Research Assistance, Carnegie Mellon University</h3>
            <p>2019.2 - 2019.7</p>
          </div>
          <div class="body">
            <p> <a href="https://hcii.cmu.edu/"> Human-Computer Interaction Institute</a> </p>
            <ul>
                <li>Worked on <a  href="https://www.norilla.com/">NoRILLA</a> project, a patented mixed-reality educational system bridging physical and virtual worlds to improve STEM learning. </li>
                <!-- <li>Published 3 paper on ICASSP, BMVC and ACM MM.</li> -->
                <!-- <li>Winner of ACCV Skeleton-based Action Recognition Challenge </li> -->
             </ul>
          </div>
        </div>

        <div class="entry">
          <div class="title">
            <h2>Graduate Student, </br> Carnegie Mellon University</h2>
            <p>2018.9 - present</p>
          </div>
          <div class="body">
            <p>Master of Science in Computer Vision</p>
            <ul>
                <li>Cumulative QPA: 4.11/4</li>
                </br>
             </ul>
          </div>
        </div>

<!--         <div class="entry">
          <div class="title">
            <h3>Research Summer Intern, Carnegie Mellon University</h3>
            <p>2017.6 - 2017.9</p>
          </div>
          <div class="body">
            <p> <a href="https://www.ri.cmu.edu/"> Robotics Institute</a> </p>
            <p>Advisor: <a href="https://www.cs.cmu.edu/~deva/">Deva Ramanan</a>, Associate Professor, </p>
            <ul>
                <li>Worked on Patch Correspondence for Interpreting Deep Neural Network.</li>
             </ul>
          </div>
        </div> -->

        <div class="entry">
          <div class="title">
            <h3>Research Assistance, Peking University</h3>
            <p>2016.2 - 2018.7</p>
          </div>
          <div class="body">
            <p>Wangxuan Institute of Computer Technology</p>
            <p> <a href=" http://www.icst.pku.edu.cn/struct/">STRUCT Group</a>  </p>
            <ul>
                <li>Worked on Skeleton-Based Action Understanding.</li>
                <!-- <li>Published 3 paper on ICASSP, BMVC and ACM MM.</li> -->
                <!-- <li>Winner of ACCV Skeleton-based Action Recognition Challenge </li> -->
             </ul>
          </div>
        </div>

        <div class="entry">
          <div class="title">
            <h2>Undergraduate Student, Peking University</h2>
            <p>2014.9 - 2018.7</p>
          </div>
          <div class="body">
            <p>Bachelor of Science in Computer Science, Summa Cum Laude</p>
            <ul>
                <li>GPA:3.59/4.0</li>
                <li>Outstanding Graduation Award of Peking University </br>and Beijing City</li>
                <li>Outstanding Student Award of Peking University</li>
             </ul>
          </div>
        </div>

      </div>
      <HR style="FILTER: alpha(opacity=100,finishopacity=0,style=3)" width="100%" color=#987cb9 SIZE=3>
        
      <h1>
        Publication
      </h1>
      <table class="proj_content" >
        <tr><td colspan="2"><p> <i>(1) Action, Actor, and an uniform way to understand. 2019-present</i> </p></td></tr>
        <tr>
          <td style="width:80%; padding-left: 10px"><p><font size="4"><b>NUTA: Non-uniform Temporal Aggregation for Action Recognition.</b></font>  <font size="3"><br/>
                  Xinyu Li*, <u>Chunhui Liu*</u>, Bing Shuai, Yi Zhu, Hao Chen, Joseph Tighe<br />
          </font>
          <!-- <font size="3"><p><i>ACM Multimedia (ACM MM) Workshop, Silicon Valley, California, U.S., Oct. 2017.</i>&nbsp;</p> -->
          <p><a href="https://arxiv.org/abs/2012.08041">PDF</a>&nbsp;&nbsp;</p></font></td>
        </tr>
        <tr>
          <td style="width:80%; padding-left: 10px"><p><font size="4"><b>A Comprehensive Study of Deep Video Action Recognition
.</b></font>  <font size="3"><br/>
                 Yi Zhu, Xinyu Li, <u>Chunhui Liu</u>, Mohammadreza Zolfaghari, Yuanjun Xiong, Chongruo Wu, Zhi Zhang, Joseph Tighe, R. Manmatha, Mu Li<br />
          </font>
          <!-- <font size="3"><p><i>ACM Multimedia (ACM MM) Workshop, Silicon Valley, California, U.S., Oct. 2017.</i>&nbsp;</p> -->
          <p><a href="https://arxiv.org/abs/2012.08041">PDF</a>&nbsp;&nbsp;</p></font></td>
        </tr>
        <tr>
          <td style="width:80%; padding-left: 10px"><p><font size="4"><b>Application of Multi-Object Tracking with Siamese Track-RCNN to the Human in Events Dataset
.</b></font>  <font size="3"><br/>
                 Bing Shuai, Andrew Berneshawi, Manchen Wang, <u>Chunhui Liu</u>, Davide Modolo, Xinyu Li, Joseph Tighe<br />
          </font>
          <font size="3"><p><i>Proceedings of the 28th ACM International Conference on Multimedia, 4625-4629  </i>&nbsp;</p>
          <p><a href="https://dl.acm.org/doi/abs/10.1145/3394171.3416297">PDF</a>&nbsp;&nbsp;</p></font></td>
        </tr>
        <tr><td colspan="2"><p> <i>(2) An interesting side-project on interpreting auto encoders. 2017</i> </p></td></tr>
        <tr>
          <td style="width:80%; padding-left: 10px"><p><font size="4"><b>Patch Correspondences for Interpreting Pixel-level CNNs</b></font>  <font size="3"><br/>
                   Victor Fragoso, <u>Chunhui Liu</u>, Aayush Bansal, Deva Ramanan<br />
          </font>
          <font size="3"><p><i>Arxiv preprint 1711.10683.</i>&nbsp;<a href="https://arxiv.org/abs/1711.10683v4">PDF</a></p>
          </tr>
          <tr><td colspan="2"></td></tr>
        <tr><td colspan="2"><p> <i>(3) Understanding Human Actions In Skeleton Domain 2016-2018 </i> </p></td></tr>
        <tr>
          <td style="width:80%; padding-left: 10px"><p><font size="4"><b>PKU-MMD: A Large Scale Benchmark for Skeleton-Based Human Action   Understanding.</b></font>  <font size="3"><br/>
                   <u>Chunhui Liu</u>, Yueyu Hu, Yanghao Li, Sijie Song, and Jiaying Liu<br />
          </font>
          <font size="3"><p><i>ACM Multimedia (ACM MM) Workshop, Silicon Valley, California, U.S., Oct. 2017.</i>&nbsp;</p>
          <p><a href="http://www.icst.pku.edu.cn/struct/Projects/PKUMMD.html">Project</a>&nbsp;&nbsp;<a href="papers/lch_mm17.pdf">PDF</a>&nbsp;&nbsp; <a href="https://github.com/ECHO960/PKU-MMD">Code</a>&nbsp;&nbsp; <a href="https://drive.google.com/drive/folders/0B20a4UzO-OyMUVpHaWdGMFY1VDQ">Dataset</a></p></font></td>
          </tr>
        <!-- <tr><td colspan="2"></td></tr> -->
        <tr>
          <td style="width:80%; padding-left: 10px"><p><font size="4"><b>Temporal Perceptive Network for Skeleton-Based Action Recognition. </b></font>  <font size="3"><br/>
                   Yueyu Hu, <u>Chunhui Liu</u>, Yanghao Li, Sijie Song and Jiaying Liu<br/>
          </font>
          <font size="3"><p><i>British Machine Vision Conference (BMVC), London, UK, Sep. 2017.</i>&nbsp;</p>
          <p><a href="papers/huyy_bmvc17.pdf">PDF</a></p></font></td>
          </tr>
        <!-- <tr><td colspan="2"></td></tr> -->
        <tr>
          <td style="width:80%; padding-left: 10px"><p><font size="4"><b>Online Action Detection and Forecast via Multi-Task Deep Recurrent   Neural Network.</b></font>  <font size="3"><br/>
                   <u>Chunhui Liu</u>, Yanghao Li, Yueyu Hu and Jiaying Liu<br/>
          </font>
          <font size="3"> <p><i>IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP2017), New Orleans, LA,  U.S., March. 2017.</i></p>
          <p><a href="http://www.icst.pku.edu.cn/struct/Projects/multitask_OAD.html">Project</a>&nbsp;&nbsp;<a href="papers/lch_icassp17.pdf">PDF</a></p></font>
          </td>
          </tr>
      </table>

      <HR style="FILTER: alpha(opacity=100,finishopacity=0,style=3)" width="100%" color=#987cb9 SIZE=3>
      
      <h1>
        Awards
      </h1>
      
          <ul>
              <li>
                  <strong>Winner</strong>,
                  <a href="http://rose1.ntu.edu.sg/ActionRecognitionChallenge/index.asp">ACCV 2016 Workshop "Large Scale 3D Human Activity Analysis Challenge in Depth Videos"</a>, 2016  
              </li>
              <li>
                  <strong>Meritorious Winner</strong>, <a href="http://www.comap.com/undergraduate/contests/">Mathematical Contest In Modeling /  Interdisciplinary Contest In Modeling (MCM/ICM)</a>, 2016
              </li>
              <li>
                  <strong>Bronze Prize</strong>, <a href="http://www.noi.cn/">National Olympiad in Informatics (NOI)</a>, 2013
              </li>
          </ul>


      <footer class="site-footer">
        <span class="site-footer-credits">
        This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman</a> theme by <a href="https://github.com/jasonlong">jasonlong</a>.</span>
      </footer>

    </section>


  </body>
</html>
